{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4dc5b904",
      "metadata": {
        "id": "4dc5b904"
      },
      "source": [
        "## Assignment 7: Train and Fine-tune a Decision Tree\n",
        "\n",
        "Please add the name, first name, immatriculation number and study program below. Each member of the group has to be added:\n",
        "- *Name: , First Name: , matr. number: , study program:.*\n",
        "- *Name:, First Name:, matr. number:, study program:.*\n",
        "- *Name:, First Name:, matr. number:, study program:.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecb8479",
      "metadata": {
        "id": "5ecb8479"
      },
      "source": [
        "In this task, you will Train and Fine-tune a Decision Tree on a real-world classification problem using the **Titanic** dataset — a historical dataset containing information about passengers on the Titanic, used to predict whether a passenger survived or not. The dataset is available through `seaborn`’s `load_dataset` function.\n",
        "\n",
        "The data includes passenger details such as:\n",
        "\n",
        "\n",
        "*   **pclass**: Ticket class (1st, 2nd, or 3rd)\n",
        "*   **sex**: Gender of the passenger\n",
        "*   **age**: Age of the passenger\n",
        "*   **fare**: Fare paid for the ticket\n",
        "*   **embarked**: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
        "*   **who**: Person type (man, woman, child)\n",
        "*   **alone**: Whether the passenger was alone or not\n",
        "\n",
        "These features are used to build predictive models that estimate a passenger’s chance of survival during the disaster."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ec253f3",
      "metadata": {
        "id": "4ec253f3"
      },
      "source": [
        "### Load the Dataset and Split the Dataset into Training and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "juxiPTYi3GW_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juxiPTYi3GW_",
        "outputId": "b2ca0089-a826-4275-af06-2021ef8e4540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Distribution:\n",
            "survived\n",
            "0    424\n",
            "1    288\n",
            "Name: count, dtype: int64\n",
            "   pclass     sex   age     fare embarked  alone  survived\n",
            "0       3    male  22.0   7.2500        S  False         0\n",
            "1       1  female  38.0  71.2833        C  False         1\n",
            "2       3  female  26.0   7.9250        S   True         1\n",
            "3       1  female  35.0  53.1000        S  False         1\n",
            "4       3    male  35.0   8.0500        S   True         0\n",
            "Training samples: 569, Test samples: 143\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic_data = sns.load_dataset('titanic')\n",
        "\n",
        "# Copy and clean the dataset\n",
        "df = titanic_data.copy()\n",
        "df = df.dropna(subset=['survived'])\n",
        "features = ['pclass', 'sex', 'age', 'fare', 'embarked', 'alone']\n",
        "df = df[features + ['survived']].dropna()\n",
        "\n",
        "# Print class distribution\n",
        "print(\"Class Distribution:\")\n",
        "print(df['survived'].value_counts())\n",
        "\n",
        "# Show the first few rows\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# Split into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff7b37b8",
      "metadata": {
        "id": "ff7b37b8"
      },
      "source": [
        "### 3.1 Hyperparameter Tuning\n",
        "\n",
        "Your task is to use the scikit-learn implementation of a decision tree classifier (DecisionTreeClassifier: https://scikit-learn.org/stable/modules/tree.html) to find the best combination of parameters. Specifically, you need to:\n",
        "\n",
        "**Test different settings of the decision tree to identify which combination gives the best cross-validation accuracy.**\n",
        "\n",
        "Explore the following parameters:\n",
        " - The maximum number of terminal nodes that controls how many \"leaves\" the tree can have.\n",
        " - The maximum depth of the tree that sets how deep the tree can grow from the root to the leaves.\n",
        " - The minimum number of samples required to split a node that defines how many samples must be in a node before it can be split into branches.\n",
        " - The function to measure the quality of a split. You should try both `gini` and `entropy` to see which gives better results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad7f3495",
      "metadata": {
        "id": "ad7f3495"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# your solution goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afe7358",
      "metadata": {
        "id": "9afe7358"
      },
      "source": [
        "### 3.2 Train and Evaluate the Best Decision Tree\n",
        "\n",
        "- #### What are the precision, recall, and F1-score on the test dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "21274e4d",
      "metadata": {
        "id": "21274e4d"
      },
      "outputs": [],
      "source": [
        "# your solution goes here\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

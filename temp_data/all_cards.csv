front,back,formula,source,tags,analogy,key_insight,technical,connections,practical,extra
What is Principal Component Analysis (PCA)?,Dimensionality reduction technique that finds linear combinations of features with maximum variance,,ML Fundamentals,PCA dimensionality-reduction,"Like finding the best camera angles to photograph a 3D sculpture - you want views that capture the most detail with fewest shots. PCA finds the ""best angles"" (principal components) in your data space.

KEY INSIGHT: High-dimensional data often lies on lower-dimensional manifolds - PCA finds linear approximations of these manifolds. Essential for avoiding curse of dimensionality in high-dim spaces.",High-dimensional data often lies on lower-dimensional manifolds - PCA finds linear approximations of these manifolds. Essential for avoiding curse of dimensionality in high-dim spaces.,,"• Related to SVD (Singular Value Decomposition) and eigendecomposition
• Used before clustering (curse of dimensionality)
• Neural networks (feature extraction) and visualization",,
What is the covariance matrix formula in PCA?,Matrix representing relationships between features,\[Cov(X) = \frac{1}{n}X^TX\],TOPICS.md,PCA covariance-matrix formula,"Like a dance partner compatibility matrix - shows which dancers move in sync.

KEY INSIGHT: Covariance matrix is a ""correlation map"" showing how features move together:
• Diagonal elements = variance of each feature
• Off-diagonal elements = covariance between features

TECHNICAL NOTES:
• X must be mean-centered first!
• Formula assumes X is (n×p) with rows=samples, cols=features","Covariance matrix is a ""correlation map"" showing how features move together:
• Diagonal elements = variance of each feature
• Off-diagonal elements = covariance between features

TECHNICAL NOTES:
• X must be mean-centered first!
• Formula assumes X is (n×p) with rows=samples, cols=features","• X must be mean-centered first!
• Formula assumes X is (n×p) with rows=samples, cols=features","• Eigendecomposition of this matrix gives principal components
• Related to correlation matrix (normalized version)",Large covariances indicate redundant features - perfect candidates for dimensionality reduction.,
How are principal components calculated?,Linear combinations of original features using eigenvectors,\[PC = X \cdot v\],TOPICS.md,PCA principal-components,"Like rotating coordinate system to align with data's natural ""grain"" - imagine wood grain patterns. Eigenvectors are like finding the main axis of a football (not round!).",,"1. Mean-center data
2. Compute covariance matrix
3. Find eigenvalues/eigenvectors
4. Sort eigenvectors by eigenvalue (largest first)
5. Project data onto top-k eigenvectors

KEY PROPERTIES:
• Each PC is orthogonal (uncorrelated)
• First PC captures most variance
• Eigenvectors (v) are ""directions of maximum variance""",,"• Face recognition (eigenfaces)
• Genomics
• Finance portfolio analysis",
What does explained variance tell us in PCA?,Proportion of dataset variance captured by each principal component,,ML Fundamentals,PCA explained-variance,"Like budgeting information - ""How much of the story does each component tell?"" Imagine explaining a movie plot - first PC gives main storyline (most important), subsequent PCs add subplots and details.

DECISION RULES:
• Keep components until cumulative explained variance reaches 90-95%
• Kaiser criterion: keep components with eigenvalue > 1
• Scree plot: look for ""elbow"" where slope flattens dramatically

KEY INSIGHT: Related to eigenvalues (larger eigenvalue = more explained variance)",Related to eigenvalues (larger eigenvalue = more explained variance),,,Trade-off between information retention and dimensionality reduction.,
What is K-means clustering?,Partitioning algorithm that divides data into k clusters by minimizing within-cluster variance,,ML Fundamentals,clustering k-means,"Like organizing a messy room by creating k boxes and putting similar items together, then adjusting box positions until items are closest to their own box.",,,"• Related to EM algorithm (hard assignment version)
• Vector Quantization, Voronoi diagrams","Market segmentation, image compression, gene sequencing",
What is the K-means objective function?,Minimize within-cluster sum of squared distances,\[\min \sum_i \sum_{x \in C_i} ||x - \mu_i||^2\],TOPICS.md,k-means objective-function,,"""Make each point as close as possible to its cluster center"" - like minimizing total walking distance in a city with k meeting points.

ALTERNATIVE NAMES:
• Within-Cluster Sum of Squares (WCSS)
• Inertia
• Distortion

TECHNICAL NOTES:
• NP-hard problem! Lloyd's algorithm finds local optima
• Usually uses Euclidean distance, but can use Manhattan, cosine similarity","• NP-hard problem! Lloyd's algorithm finds local optima
• Usually uses Euclidean distance, but can use Manhattan, cosine similarity","• Related to variance decomposition - minimizing within-cluster variance
• Similar to expectation in EM algorithm",Elbow method plots WCSS vs k to find optimal number of clusters,
How do you update centroids in K-means?,Take the mean of all points assigned to each cluster,\[\mu_i = \frac{1}{|C_i|} \sum_{x \in C_i} x\],TOPICS.md,k-means centroid-update,"Like finding the ""center of mass"" or ""balance point"" of each group - if you put weights at each data point, where would you place the fulcrum?

MATHEMATICAL INSIGHT: Mean minimizes sum of squared distances - this is why K-means uses Euclidean distance.

ALGORITHM ROLE: This is the M-step (Maximization) in Lloyd's algorithm, alternates with E-step (assignment).",,,,,
What are the two steps of Lloyd's K-means algorithm?,Assignment step (assign points to nearest centroid) and Update step (recalculate centroids),,ML Fundamentals,k-means lloyds-algorithm,"Like a dance where partners (points) choose their favorite dancer (centroid), then dancers move to the center of their group, repeat until everyone is happy.

ALGORITHM STEPS:
• E-STEP (Assignment): Hard assignment - each point belongs to exactly one cluster (contrast with soft assignment in EM)
• M-STEP (Update): Recalculate centroids as means",,,"• Similar to EM algorithm structure
• Coordinate descent optimization",,
What is the EM algorithm?,Expectation-Maximization algorithm for finding parameters when latent variables exist,,ML Fundamentals,EM algorithm latent-variables,"Like trying to learn two things at once - ""If I knew which cluster each point belonged to, I could estimate cluster parameters. If I knew cluster parameters, I could assign points to clusters."" EM solves this circular dependency.

KEY CONCEPT: Latent variables - hidden/unobserved variables (like cluster membership)",Latent variables - hidden/unobserved variables (like cluster membership),,"• Generalizes K-means (soft assignment vs hard)
• Related to variational inference","• Gaussian Mixture Models
• Hidden Markov Models
• Factor analysis
• Missing data imputation",
What is the E-step in EM algorithm?,Calculate expectation of log-likelihood given current parameters,"\[Q(θ|θ^{(t)}) = E[\log L(θ|X,Z)|X,θ^{(t)}]\]",TOPICS.md,EM e-step expectation,,"""Given my current model, how likely is each data point to belong to each cluster?""

KEY CONCEPT: Computes soft assignments (probabilities) rather than hard assignments

GAUSSIAN MIXTURE EXAMPLE: For each point, calculate probability it came from each Gaussian component using current means/covariances",Takes expectation over latent variables Z given observed data X and current parameters,"• Similar to K-means assignment step but with probabilities
• Creates ""responsibility"" matrix showing how responsible each cluster is for each point",,
What is the M-step in EM algorithm?,Find parameters that maximize the expectation from E-step,\[θ^{(t+1)} = \arg\max Q(θ|θ^{(t)})\],TOPICS.md,EM m-step maximization,,"""Given these soft assignments, what are the best parameters for my model?""

KEY CONCEPT: Uses weighted versions of standard estimators

GAUSSIAN MIXTURE EXAMPLE:
• Update means using weighted averages (weights = responsibilities from E-step)
• Update covariances using weighted sample covariances

WEIGHTED UPDATES: Each data point contributes to parameter estimates proportional to its assignment probability",,"• Generalizes K-means centroid update (hard weights vs soft weights)
• Maximum likelihood estimation with weighted data",,
What is a neural network?,"Computational model inspired by biological neurons, with layers of interconnected nodes",,ML Fundamentals,neural-networks definition,"Like a simplified brain where artificial neurons receive signals, process them, and pass signals forward. Each connection has a ""strength"" (weight).",,,"• Generalize linear regression (single layer = linear regression)
• Logistic regression (single layer + sigmoid)","Image recognition, NLP, game playing, drug discovery",
What is the forward pass in neural networks?,Process of computing output by propagating input through network layers,\[h = \sigma(Wx + b)\],TOPICS.md,neural-networks forward-pass,"Like a factory assembly line where each layer transforms the input, passing it to the next station. Raw materials (input) → processed goods (hidden layers) → final product (output).",,"Matrix operations are highly parallelizable, efficient on GPUs | • Layer-by-layer: Output of layer i becomes input to layer i+1
• Information flow: Only forward direction during inference (no feedback loops like RNNs)",,,
What is backpropagation?,Algorithm for computing gradients of loss function with respect to network weights,\[\frac{\partial L}{\partial W} = \frac{\partial L}{\partial h} \cdot \frac{\partial h}{\partial W}\],TOPICS.md,neural-networks backpropagation,"Like tracing responsibility for a mistake backwards through a company hierarchy - ""How much did each department contribute to the final error?""

MATHEMATICAL BASIS: Chain rule - technique for computing derivatives of composite functions",,"1. Forward pass computes predictions
2. Compute loss
3. Backward pass computes gradients
4. Update weights",,,
What is the ReLU activation function?,"Rectified Linear Unit: outputs input if positive, zero otherwise","\[ReLU(x) = \max(0, x)\]",ML Fundamentals,neural-networks activation-function relu,"Like an electrical switch - if signal is positive, let it through; if negative, block it completely.",,"• Gradient: ∂ReLU/∂x = 1 if x>0, else 0 (undefined at 0, usually set to 0)
• Somewhat resembles biological neuron firing patterns",,,
What is gradient descent?,Optimization algorithm that iteratively updates parameters in direction of steepest descent,\[θ = θ - α∇J(θ)\],ML Fundamentals,optimization gradient-descent,"Like hiking down a mountain in fog - you can only see your immediate surroundings, so you always step in the steepest downward direction.

LEARNING RATE (α): Step size - too large and you overshoot the valley, too small and training is slow",,,,,
What is linear regression?,Statistical method for modeling relationship between dependent variable and independent variables,\[y = β_0 + β_1x_1 + β_2x_2 + ... + ε\],ML Fundamentals,linear-regression supervised-learning,,"Finding the ""best-fit line"" through data points - like drawing a straight line through a scatter plot that minimizes distances to points.",,"Foundation for logistic regression, neural networks (single layer), polynomial regression",,
What is the normal equation for linear regression?,Closed-form solution for optimal parameters,\[β = (X^TX)^{-1}X^Ty\],ML Fundamentals,linear-regression normal-equation,,,,,"• Small datasets
• Few features (<10k)
• Want exact solution",
What is Ridge regression?,Linear regression with L2 regularization to prevent overfitting,\[\hat{β} = (X^TX + λI)^{-1}X^Ty\],TOPICS.md,ridge-regression regularization,Like speed limits for coefficients - prevents any single coefficient from becoming too large and dominating the model.,,,,,
What is the difference between Ridge and Lasso regression?,"Ridge uses L2 penalty (squared weights), Lasso uses L1 penalty (absolute weights)",,ML Fundamentals,regularization ridge lasso,,"Ridge constraint is a circle (smooth), Lasso is a diamond (corners). Corners of diamond cause coefficients to hit exactly zero.

FEATURE SELECTION:
• Lasso: Automatically selects features (sparse solutions)
• Ridge: Keeps all features but shrinks them

CORRELATED FEATURES:
• Ridge: Spreads weights evenly among correlated features
• Lasso: Arbitrarily picks one","• Ridge: Has closed-form solution
• Lasso: Requires iterative algorithms

ELASTIC NET: Combines both penalties - L1 for sparsity, L2 for groupings

WHEN TO USE:
• Lasso: When you believe few features matter
• Ridge: When many features contribute",,"• Lasso: When you believe few features matter
• Ridge: When many features contribute",
What is logistic regression?,Classification algorithm using logistic function to model probability of binary outcomes,\[p = \frac{1}{1 + e^{-z}}\],ML Fundamentals,logistic-regression classification,"Like a smooth switch that gradually transitions from 0 to 1, instead of linear regression's unlimited range.

LINEAR PREDICTOR: z = β₀ + β₁x₁ + β₂x₂ + ... (same as linear regression)

SIGMOID FUNCTION: Maps any real number to (0,1) interval - perfect for probabilities!

DECISION BOUNDARY: When p = 0.5, z = 0, so β₀ + β₁x₁ + ... = 0 defines boundary

ODDS INTERPRETATION: log(p/(1-p)) = z, so coefficients represent log-odds ratios",,,"• Generalized Linear Model (GLM)
• Neural network with single layer + sigmoid activation",,
What is the softmax function?,Generalization of logistic function for multi-class classification,\[p_i = \frac{\exp(w_i^T x)}{\sum_j \exp(w_j^T x)}\],TOPICS.md,logistic-regression softmax multi-class,"Like a talent competition where each class ""competes"" with a score (w_i^T x), and probabilities are determined by relative performance.",,,"• Reduces to sigmoid for binary case
• Used as final layer in neural networks for classification",Often used with cross-entropy loss and one-hot encoded targets,
What is entropy in decision trees?,Measure of impurity or randomness in a dataset,\[H(S) = -\sum p_i \log_2(p_i)\],TOPICS.md,decision-trees entropy,"Like measuring ""surprise"" in a message - if all examples are same class (pure), entropy = 0 (no surprise). If equal mix of classes, entropy is maximum (most surprise).

DECISION MAKING: Entropy guides tree splits - we want to ask questions that reduce uncertainty the most

BINARY EXAMPLE:
• 50-50 split has entropy = 1 bit
• 90-10 split has entropy ≈ 0.47 bits",,,"• Related to information gain, Gini impurity (similar concept)
• Shannon information theory",Lower entropy after split means better question/split,
What is information gain?,Reduction in entropy after splitting on an attribute,"\[IG(S,A) = H(S) - \sum \frac{|S_v|}{|S|} H(S_v)\]",TOPICS.md,decision-trees information-gain,,,,,,Used to select best attribute for splitting at each node
What is Gini impurity?,Alternative to entropy for measuring node impurity,\[Gini = 1 - \sum p_i^2\],ML Fundamentals,decision-trees gini-impurity,,,,,,"Computationally faster than entropy, similar results"
What is Random Forest?,Ensemble method combining multiple decision trees with bagging,,ML Fundamentals,ensemble random-forest decision-trees,,,,,,Reduces variance and overfitting compared to single decision tree
What is Support Vector Machine (SVM)?,Classification algorithm that finds optimal hyperplane maximizing margin between classes,,ML Fundamentals,SVM classification margin,"Like drawing the widest possible ""no man's land"" between two armies - points closest to border (support vectors) determine the boundary.

GEOMETRIC INTUITION:
• In 2D: Finds line with maximum distance to nearest points from each class
• In higher dimensions: Finds hyperplane

SPARSE SOLUTION: Only support vectors matter for decision boundary - can ignore all other training points!","• In 2D: Finds line with maximum distance to nearest points from each class
• In higher dimensions: Finds hyperplane

SPARSE SOLUTION: Only support vectors matter for decision boundary - can ignore all other training points!",,,,
What is the SVM primal objective function?,Minimize weights while allowing some misclassification,\[\min \frac{1}{2}||w||^2 + C\sum ξ_i\],TOPICS.md,SVM primal objective,,,,,,C controls trade-off between margin size and misclassification penalty
What is the SVM constraint?,Points must be on correct side of margin or pay penalty,\[y_i(w^Tx_i + b) ≥ 1 - ξ_i\],TOPICS.md,SVM constraint slack-variables,,,,,,ξᵢ are slack variables allowing soft margin
What is the kernel trick in SVM?,Technique to implicitly map data to higher-dimensional space for non-linear classification,,ML Fundamentals,SVM kernel-trick,,,,,,"Common kernels: linear, polynomial, RBF (Gaussian)"
What is Naive Bayes classifier?,Probabilistic classifier based on Bayes theorem with strong independence assumption,\[P(C|X) = \frac{P(X|C)P(C)}{P(X)}\],ML Fundamentals,naive-bayes classification bayes-theorem,,,,,,Assumes features are conditionally independent given class
What is the naive independence assumption?,Features are conditionally independent given the class label,"\[P(x_1,...,x_n|C) = \prod P(x_i|C)\]",ML Fundamentals,naive-bayes independence-assumption,,,,,,Simplifies computation but often violated in practice
What is Laplace smoothing?,Technique to handle zero probabilities by adding small constant to counts,"\[P(x_i|C) = \frac{count(x_i,C) + α}{count(C) + α|V|}\]",ML Fundamentals,naive-bayes laplace-smoothing,,,,,,"α is smoothing parameter (usually 1), |V| is vocabulary size"
What is the bias-variance tradeoff?,Fundamental tradeoff between model complexity and generalization ability,\[Error = Bias^2 + Variance + Noise\],ML Fundamentals,bias-variance tradeoff,"Archery target
• Bias = systematic error (consistently missing target in same direction)
• Variance = inconsistency (shots scattered around)",,,,,
What is bias in machine learning?,Error from overly simplistic assumptions in learning algorithm,,ML Fundamentals,bias underfitting,,,,,,High bias leads to underfitting and poor performance on training data
What is variance in machine learning?,Error from sensitivity to small fluctuations in training set,,ML Fundamentals,variance overfitting,,,,,,High variance leads to overfitting and poor generalization
What is Bayes error?,Lowest possible error rate for any classifier on a given problem,,ML Fundamentals,bayes-error irreducible-error,,,,,,Represents irreducible error due to noise and overlapping classes
What is accuracy?,Fraction of correct predictions out of total predictions,\[Accuracy = \frac{TP + TN}{TP + TN + FP + FN}\],ML Fundamentals,evaluation accuracy,,"""How often is the model right?""

IMBALANCED DATA TRAP: 99% accuracy sounds great, but if 99% of data is negative class, a ""always predict negative"" model achieves this!

MEDICAL EXAMPLE: Cancer screening with 1% cancer rate - 99% accuracy might mean missing all cancer cases",,,,
What is precision?,Fraction of true positives among predicted positives,\[Precision = \frac{TP}{TP + FP}\],TOPICS.md,evaluation precision,"Like quality control in manufacturing - ""Of all products we labeled as 'good', what fraction actually are good?""",,,,"• Email spam: High precision means few legitimate emails marked as spam
• Medical: High precision means few healthy patients diagnosed with disease

TRADE-OFF: Increasing precision often decreases recall (fewer positive predictions overall)

EXTREME CASE: Predict positive only when 100% certain → perfect precision but terrible recall",
What is recall (sensitivity)?,Fraction of true positives among actual positives,\[Recall = \frac{TP}{TP + FN}\],TOPICS.md,evaluation recall sensitivity,"""Of all people who are actually lost, how many did we find?"" Missing people (false negatives) is catastrophic.",,,,"• Medical screening: High recall means catching most disease cases, even if some false alarms
• Security: Airport screening prioritizes recall - better to flag innocent travelers than miss threats",
What is F1-score?,Harmonic mean of precision and recall,\[F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}\],TOPICS.md,evaluation f1-score,"Like finding the sweet spot between two competing goals - quality (precision) vs completeness (recall).

HARMONIC MEAN: Penalizes extreme values more than arithmetic mean - if either precision or recall is low, F1 is low",,,,,
What is specificity?,Fraction of true negatives among actual negatives,\[Specificity = \frac{TN}{TN + FP}\],ML Fundamentals,evaluation specificity,,,,,,"Answers: Of all actual negatives, how many were correctly identified?"
What are the 6 phases of CRISP-DM?,"Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, Deployment",,ML Fundamentals,CRISP-DM methodology,,,,,,Iterative process for data mining projects
What is data normalization?,"Scaling features to have similar ranges, typically [0,1]",\[x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}}\],ML Fundamentals,preprocessing normalization,,,,,,Prevents features with large scales from dominating
What is data standardization?,Scaling features to have zero mean and unit variance,\[x_{std} = \frac{x - μ}{σ}\],ML Fundamentals,preprocessing standardization z-score,,,,,,"Results in standard normal distribution (mean=0, std=1)"
What is cross-validation?,Technique for assessing model performance by splitting data into multiple train/validation sets,,ML Fundamentals,evaluation cross-validation,,,,,,"K-fold CV divides data into k subsets, trains k times"
What is overfitting?,Model performs well on training data but poorly on unseen data,,ML Fundamentals,overfitting generalization,"Like a student who memorizes textbook problems perfectly but fails on new exam questions - learned specific examples, not general principles.",,,,,
What is underfitting?,Model is too simple to capture underlying patterns in data,,ML Fundamentals,underfitting bias,Like trying to describe a symphony with only three notes - missing essential complexity.,,,,,
What is a convolutional layer in CNNs?,Layer that applies filters/kernels to detect local features while preserving spatial relationships,,Neural Networks,CNN convolutional-layer,,,,,,Uses shared weights and local connectivity to reduce parameters
What is pooling in CNNs?,Downsampling operation that reduces spatial dimensions while retaining important features,,Neural Networks,CNN pooling,,,,,,"Max pooling takes maximum value, average pooling takes mean value in each region"
What are CNN filters/kernels?,"Small matrices that slide over input to detect specific features like edges, textures, or patterns",,Neural Networks,CNN filters kernels,,,,,,Each filter learns to detect different features through backpropagation
What is stride in convolution?,Step size when moving the filter across the input - larger stride means smaller output,\[Output\_size = \frac{Input\_size - Filter\_size + 2*Padding}{Stride} + 1\],Neural Networks,CNN stride convolution,,,,,,"Stride of 1 preserves most spatial information, stride >1 reduces output size"
What is Mean Squared Error (MSE)?,Loss function measuring average squared differences between predicted and actual values,\[MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2\],ML Fundamentals,loss-function MSE regression,,,,,,"Used for regression problems, penalizes large errors more heavily"
What is cross-entropy loss?,Loss function measuring difference between predicted and actual probability distributions,\[CE = -\sum_{i=1}^{n} y_i \log(\hat{y_i})\],ML Fundamentals,loss-function cross-entropy classification,,,,,,"Used for classification, works well with softmax activation"
When to use MSE vs cross-entropy loss?,"MSE for regression problems (continuous outputs), cross-entropy for classification problems (probability outputs)",,ML Fundamentals,loss-function selection,,,,,,Choice depends on problem type and output layer activation function
What is the sigmoid activation function?,"Activation function that squashes input to range (0,1), commonly used for binary classification",\[\sigma(x) = \frac{1}{1 + e^{-x}}\],Neural Networks,activation-function sigmoid,,,,,,Can cause vanishing gradient problem in deep networks
What is the tanh activation function?,"Activation function that squashes input to range (-1,1), zero-centered version of sigmoid",\[tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}\],Neural Networks,activation-function tanh,,,,,,Often works better than sigmoid due to zero-centered output
What is dropout in neural networks?,Regularization technique that randomly sets some neurons to zero during training to prevent overfitting,,Neural Networks,regularization dropout,,,,,,"Forces network to not rely on specific neurons, improves generalization"
What is batch normalization?,Technique that normalizes layer inputs to accelerate training and reduce internal covariate shift,\[BN(x) = \gamma \frac{x - \mu}{\sigma} + \beta\],Neural Networks,batch-normalization training,,,,,,Allows higher learning rates and makes network less sensitive to initialization
How do you determine the number of principal components to keep?,"Use scree plot (elbow method), cumulative explained variance threshold (e.g., 90%), or Kaiser criterion (eigenvalues > 1)",\[Cumulative\_Var = \frac{\sum_{i=1}^{k} \lambda_i}{\sum_{i=1}^{n} \lambda_i}\],PCA,PCA component-selection scree-plot,,,,,,Balance between dimensionality reduction and information preservation
What preprocessing is required before PCA?,"Standardize features to have zero mean and unit variance, handle missing values",\[z = \frac{x - \mu}{\sigma}\],PCA,PCA preprocessing standardization,,,,,,"Without standardization, features with larger scales dominate the principal components"
What are the assumptions and limitations of PCA?,"Assumes linear relationships, sensitive to scaling, components may not be interpretable, requires numerical data",,PCA,PCA assumptions limitations,,,,,,Works best when variables are correlated and relationships are linear
What is the elbow method for determining optimal k?,"Plot within-cluster sum of squares (WCSS) vs k, look for elbow where rate of decrease slows significantly",,Clustering,k-means elbow-method optimal-k,,,,,,Point where adding more clusters doesn't significantly reduce WCSS
What is K-means++ initialization?,Smart initialization that chooses initial centroids far apart to improve convergence,,Clustering,k-means initialization k-means++,,,,,,"First centroid random, subsequent ones chosen proportional to squared distance from nearest existing centroid"
What are the main limitations of K-means?,"Assumes spherical clusters, sensitive to initialization, requires pre-specifying k, sensitive to outliers",,Clustering,k-means limitations,,,,,,"Struggles with varying cluster sizes, non-spherical clusters, and different densities"
What is ROC curve?,Plot of True Positive Rate vs False Positive Rate at various classification thresholds,"\[TPR = \frac{TP}{TP+FN}, FPR = \frac{FP}{FP+TN}\]",Evaluation,evaluation ROC classification,,,,,,Shows trade-off between sensitivity and specificity across all thresholds
What is AUC in classification?,Area Under ROC Curve - measures model's ability to distinguish between classes (0.5-1.0),,Evaluation,evaluation AUC classification,,,,,"Good baseline metric, but supplement with precision-recall for imbalanced datasets",
What is R² (coefficient of determination)?,Measures proportion of variance in dependent variable explained by independent variables,\[R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\],Evaluation,evaluation r-squared regression,,,,,,"R² = 1 means perfect fit, R² = 0 means model no better than mean"
What are residuals in regression?,Differences between observed and predicted values used to assess model assumptions,\[e_i = y_i - \hat{y_i}\],Evaluation,regression residuals evaluation,,,,,,"Residual plots help identify heteroscedasticity, non-linearity, and outliers"
What are Type I and Type II errors?,Type I: False Positive (rejecting true null hypothesis). Type II: False Negative (accepting false null hypothesis),,Statistics,statistics type-1-error type-2-error,,,,,,Trade-off controlled by decision threshold - lowering threshold reduces Type II but increases Type I
What is statistical significance in ML?,Measure of whether observed difference in model performance is likely due to chance,,Statistics,statistics significance hypothesis-testing,,,,,,Use paired t-test on CV scores or McNemars test for classification comparisons
What is data leakage?,Information from future or target variable inappropriately leaking into features during training,,Data Preprocessing,data-leakage preprocessing,,,,,,"Prevent by proper train/test split timing, avoiding future information, careful feature engineering"
What is hyperparameter tuning?,Process of finding optimal hyperparameter values using techniques like grid search or random search,,Model Selection,hyperparameter-tuning optimization model-selection,,,,,,Use nested cross-validation to avoid overfitting to validation set
How to handle class imbalance?,"Use techniques like SMOTE, stratified sampling, cost-sensitive learning, or balanced evaluation metrics",,Classification,classification class-imbalance,,,,,,"Accuracy can be misleading with imbalanced data - use precision, recall, F1-score instead"
What is silhouette score?,Cluster validation metric measuring how similar points are to their own cluster vs other clusters,"\[s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}\]",Clustering,clustering silhouette-score validation,,,,,,"Values range from -1 to 1, higher values indicate better clustering"
What is feature importance in ML?,Measure of how much each feature contributes to model predictions,,Model Interpretability,feature-importance interpretability,,,,,,"Can be calculated using permutation importance, SHAP values, or model-specific methods"
What is the difference between bagging and boosting?,"Bagging trains models in parallel on bootstrap samples. Boosting trains models sequentially, each correcting previous errors",,Ensemble Methods,ensemble bagging boosting,,,,,,"Bagging reduces variance (Random Forest), boosting reduces bias (AdaBoost, XGBoost)"
What is hard vs soft voting in ensembles?,Hard voting: majority class vote. Soft voting: average predicted probabilities,,Ensemble Methods,ensemble voting,,,,,,Soft voting generally performs better when base models output calibrated probabilities
What is automatic differentiation in PyTorch?,Computational technique that automatically computes gradients for backpropagation,,PyTorch,pytorch automatic-differentiation,,,,,,Tracks operations on tensors to build computational graph for gradient computation
What are PyTorch tensors?,Multi-dimensional arrays similar to NumPy arrays but with GPU acceleration and automatic differentiation,,PyTorch,pytorch tensors,,,,,,Foundation of PyTorch - support operations needed for neural network computations
What is the key relationship between sigmoid and tanh activation functions?,"tanh(a) = 2×σ(2a) - 1, where σ is the sigmoid function",\[\tanh(a) = 2 \cdot \frac{1}{1 + e^{-2a}} - 1 = \frac{e^a - e^{-a}}{e^a + e^{-a}}\],Assignment 10 - Activation Functions,activation-functions sigmoid tanh neural-networks,,,,,,"This relationship shows that tanh is a scaled and shifted version of sigmoid. Tanh outputs range from -1 to 1 (zero-centered), while sigmoid outputs range from 0 to 1. The zero-centered property of tanh often makes training more stable by preventing bias in gradient directions, especially in deeper networks where gradients can accumulate."
Why can't a single neuron solve the XOR problem?,"A single neuron can only create linear decision boundaries, but XOR requires a non-linear boundary to separate the classes","\[\text{XOR: } (0,0) \rightarrow 0, (0,1) \rightarrow 1, (1,0) \rightarrow 1, (1,1) \rightarrow 0\]",Assignment 10 - Single Neuron Limitations,xor-problem linear-separability single-neuron limitations,,,,,,"The XOR function cannot be separated by any single straight line. Points (0,1) and (1,0) both output 1, while (0,0) and (1,1) both output 0 - they're diagonally opposite. This classic problem historically motivated the development of multi-layer perceptrons. It demonstrates that linear models (including single neurons) have fundamental representational limitations."
What is the forward propagation formula for a single neuron?,"z = Σ(wi × xi) + b, then output = σ(z) where σ is the activation function",\[z = \mathbf{w}^T \mathbf{x} + b \quad \text{and} \quad y = \sigma(z) = \frac{1}{1 + e^{-z}}\],Assignment 10 - Single Neuron,forward-propagation neuron weighted-sum activation,,,,,,"Forward propagation is the process of computing a neuron's output. First, compute the weighted sum of inputs plus bias (linear combination). Then apply a non-linear activation function like sigmoid. This two-step process (linear → non-linear) is what gives neural networks their power. Without the activation function, multiple layers would collapse to a single linear transformation."
What is the key insight behind backpropagation in neural networks?,"Use the chain rule to compute gradients layer by layer, propagating error backwards from output to input",\[\frac{\partial L}{\partial w_i} = \frac{\partial L}{\partial z} \cdot \frac{\partial z}{\partial w_i} = \delta \cdot x_i\],Assignment 10 - Backpropagation,backpropagation chain-rule gradients training,,,,,,"Backpropagation applies calculus chain rule to efficiently compute gradients in multi-layer networks. The error signal δ flows backwards through the network, with each layer computing its contribution to the total error. This allows updating all parameters simultaneously. The algorithm's efficiency (O(n) where n is network size) made training deep networks practical and sparked the deep learning revolution."
How do hidden layers enable neural networks to solve non-linear problems like XOR?,"Hidden layers create internal representations that transform the input space, making non-linearly separable problems linearly separable in the hidden space","\[\mathbf{h} = \sigma(\mathbf{W_1} \mathbf{x} + \mathbf{b_1}), \quad y = \sigma(\mathbf{W_2} \mathbf{h} + b_2)\]",Assignment 10 - Multi-layer Networks,hidden-layers representation-learning non-linear multi-layer,,,,,,"Hidden layers act as feature detectors that learn useful internal representations. For XOR, hidden neurons might learn to detect patterns like 'exactly one input is 1' or 'both inputs are the same'. These learned features transform the problem into a space where a linear classifier (output layer) can succeed. This is the core principle behind deep learning: hierarchical feature learning."
What is binary cross-entropy loss and why is it used for binary classification?,L = -[y×log(ŷ) + (1-y)×log(1-ŷ)]. It penalizes confident wrong predictions more heavily and has nice mathematical properties for gradient descent,\[L = -\frac{1}{m} \sum_{i=1}^{m} [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]\],Assignment 10 - Loss Functions,binary-cross-entropy loss-function classification training,,,,,,"Binary cross-entropy is the maximum likelihood loss for Bernoulli distributions. It heavily penalizes confident wrong predictions (when model outputs 0.9 but true label is 0). The logarithmic nature ensures the gradient flows properly for sigmoid outputs. As predictions approach the correct class, loss approaches 0; as they approach the wrong class, loss approaches infinity, providing strong learning signals."
What is the vanishing gradient problem and how does choice of activation function affect it?,"Gradients become exponentially smaller in deeper layers. Sigmoid derivatives max at 0.25, causing gradients to shrink. Tanh (max derivative 1) and ReLU help mitigate this","\[\sigma'(z) = \sigma(z)(1-\sigma(z)) \leq 0.25, \quad \tanh'(z) = 1-\tanh^2(z) \leq 1\]",Assignment 10 - Activation Functions,vanishing-gradients activation-functions deep-networks training,,,,,,"In deep networks, gradients multiply through layers during backpropagation. If each layer's gradient is less than 1, the product becomes exponentially small, making early layers learn very slowly. Sigmoid's maximum derivative is 0.25, so gradients can shrink by 75% per layer. Tanh is better (max derivative 1), and ReLU avoids saturation entirely. This insight drives modern activation function choices."
What are the key differences between training single neurons vs multi-layer networks?,"Single neurons: simple gradient computation, linear boundaries only. Multi-layer: requires backpropagation through layers, can learn non-linear patterns, more complex optimization landscape","\[\text{Single: } \frac{\partial L}{\partial w} = (\hat{y}-y) \cdot x, \quad \text{Multi: } \frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial W_2} \cdot \frac{\partial W_2}{\partial h} \cdot \frac{\partial h}{\partial W_1}\]",Assignment 10 - Network Architectures,single-neuron multi-layer training complexity architecture,,,,,,"Single neurons have convex loss landscapes and guaranteed convergence to global minimum. Multi-layer networks have non-convex loss surfaces with many local minima, requiring careful initialization and learning rates. However, this complexity enables universal approximation - multi-layer networks can theoretically approximate any continuous function. The trade-off is between simplicity/interpretability (single neuron) and expressiveness (multi-layer)."
What is the mathematical formula for 2D convolution output size with padding and stride?,Output size = (Input size + 2×Padding - Filter size) / Stride + 1,\[O = \frac{I + 2P - F}{S} + 1\],Assignment 11 - Convolutional Operations,convolution cnn padding stride,,,,,,"Critical for designing CNN architectures. For example, with input 32×32, filter 3×3, padding 1, stride 1: output = (32+2-3)/1+1 = 32×32 (preserves size). Without padding: (32-3)/1+1 = 30×30 (shrinks). This formula determines spatial dimensions throughout your network - essential for connecting layers properly."
What are the key components needed to train a CNN in PyTorch?,"Model (nn.Module), Loss function (criterion), Optimizer, Data loaders, Training loop with forward/backward passes",,Assignment 11 - PyTorch Training,pytorch training cnn workflow,,,,,,"Essential PyTorch workflow: 1) Define model inheriting nn.Module with __init__ and forward() 2) Create criterion (e.g., CrossEntropyLoss) 3) Set optimizer (e.g., Adam) 4) Loop: optimizer.zero_grad() → forward pass → loss.backward() → optimizer.step(). Like cooking: recipe (model), ingredients (data), technique (optimizer), process (training loop)."
What effects do different convolutional filters have on images?,"Edge detection (gradients), blurring (smoothing), sharpening (high-pass), and directional features depending on filter weights",,Assignment 11 - Filter Effects,convolution filters edge-detection image-processing,,,,,,"Filters extract features: Vertical edge detector [-1,0,1; -1,0,1; -1,0,1] finds vertical edges. Horizontal [−1,−1,−1; 0,0,0; 1,1,1] finds horizontal edges. Gaussian blur smooths images. Sharpening enhances edges. Think of filters as specialized 'lenses' - each sees different aspects of the image, like how different camera filters emphasize colors or textures."
How do you improve CNN performance beyond the baseline architecture?,"Data augmentation, deeper networks, dropout regularization, better optimizers, learning rate scheduling, residual connections",,Assignment 11 - Model Improvement,cnn optimization performance data-augmentation,,,,,,"Multi-pronged approach: 1) Data augmentation (rotation, flipping, cropping) increases effective dataset size 2) Architectural improvements (more layers, dropout, residual connections) 3) Training improvements (Adam optimizer, learning rate scheduling, early stopping). Like improving athletic performance: better training data (augmentation), better technique (architecture), better coaching (optimization)."
What is the purpose of data normalization in CNN preprocessing?,Standardizes input values to improve training stability and convergence speed,\[x_{norm} = \frac{x - \mu}{\sigma}\],Assignment 11 - Data Preprocessing,normalization preprocessing cnn training,,,,,,"CIFAR-10 typically normalized to [-1,1] using mean=0.5, std=0.5 for each RGB channel. This prevents certain features from dominating due to scale differences and helps gradients flow better during backpropagation. Like standardizing test scores - puts all inputs on equal footing so the network can learn patterns rather than being distracted by scale differences."
What is the role of MaxPooling in CNN architectures?,"Reduces spatial dimensions, provides translation invariance, and reduces computational cost while retaining important features",,Assignment 11 - CNN Architecture,maxpooling cnn dimensionality-reduction,,,,,,"MaxPooling takes maximum value in each region (typically 2×2), reducing 32×32 to 16×16. Benefits: 1) Reduces parameters and computation 2) Provides translation invariance (small shifts don't change output) 3) Focuses on strongest activations. Trade-off: loses spatial precision. Like summarizing a paragraph by keeping only the most important words - you lose detail but keep the essence."
How do you evaluate model performance during CNN training?,"Monitor training/validation loss and accuracy, use separate test set for final evaluation, watch for overfitting signs",\[Accuracy = \frac{Correct Predictions}{Total Predictions}\],Assignment 11 - Model Evaluation,evaluation accuracy overfitting validation,,,,,,"Key metrics: Training loss should decrease steadily. Validation accuracy should improve initially. If training accuracy >> validation accuracy, you're overfitting. Test set gives final unbiased performance estimate. Use techniques like early stopping, dropout, or regularization if overfitting occurs. Like studying for exams: practice tests (validation) help adjust strategy, but final grade (test set) is what matters."
"What is the relationship between stride, padding, and output spatial dimensions in CNNs?","Stride controls downsampling rate, padding preserves spatial dimensions, together they determine output size according to the convolution formula",\[Output = \frac{Input + 2 \times Padding - Kernel}{Stride} + 1\],Assignment 11 - CNN Spatial Dimensions,stride padding convolution spatial-dimensions,,,,,,"Design trade-offs: Stride=1 preserves resolution but increases computation. Stride=2 halves dimensions, reducing computation but losing spatial detail. Padding='same' keeps dimensions constant, padding=0 shrinks output. Example: 64×128 input with 3×3 kernel, stride=1, padding=1 gives 64×128 output. Critical for designing networks where layer outputs must match expected input dimensions."
When should you use median vs mean for missing value imputation?,Use median when data has outliers or is skewed; use mean for normally distributed data without outliers,,Assignment 1 - Preprocessing,preprocessing missing-values imputation,,,,,,"PRACTICAL EXAMPLE: In Boston Housing dataset, median was chosen for RM, AGE, TAX because housing prices are skewed and contain outliers. Mean would be pulled by extreme values and give unrealistic imputations.

DECISION FRAMEWORK:
• Median: Robust to outliers, preserves typical values
• Mean: Sensitive to outliers, assumes normal distribution
• Mode: For categorical data

IMPACT: Wrong choice can introduce bias and affect model performance downstream."
What is the IQR method for outlier detection?,Data points outside Q1 - 1.5×IQR or Q3 + 1.5×IQR bounds are considered outliers,\[Outliers: x < Q1 - 1.5 \times IQR \text{ or } x > Q3 + 1.5 \times IQR\],Assignment 1 - Preprocessing,preprocessing outliers IQR statistics,"Like defining 'normal' height range - most people fall within expected range, very short or very tall people are outliers.

PRACTICAL APPLICATION: In crime rate analysis (CRIM feature), IQR method identified neighborhoods with extremely high crime as outliers, but these may be valid data points representing dangerous areas.",,,,"In crime rate analysis (CRIM feature), IQR method identified neighborhoods with extremely high crime as outliers, but these may be valid data points representing dangerous areas.",
Why is data type correction important in preprocessing?,Incorrect data types (strings stored as objects) prevent mathematical operations and can cause silent failures in ML algorithms,,Assignment 1 - Preprocessing,preprocessing data-types pandas,,,,,,"REAL-WORLD PROBLEM: In Boston Housing dataset, CRIM and ZN columns were stored as quoted strings ('0.02731') instead of floats.

CONSEQUENCES OF NOT FIXING:
• Mathematical operations fail silently
• Algorithms may treat numbers as categories
• Correlation analysis produces wrong results
• Model training fails with cryptic errors

SOLUTION PATTERN:
1. Use df.info() to inspect data types
2. Strip quotes with str.strip('""')
3. Convert with astype(float)
4. Verify with df.info() again

PREVENTION: Always check data types after loading any dataset"
What does high correlation between features indicate and how should you handle it?,"High correlation indicates multicollinearity - features contain redundant information. Consider combining, removing one, or using regularization",,Assignment 1 - Preprocessing,preprocessing correlation multicollinearity feature-engineering,,,,,,"EXAMPLE FROM ASSIGNMENT: TAX and RAD had 0.89 correlation in Boston Housing data - both relate to urban accessibility and development.

WHY IT MATTERS:
• Redundant features don't improve model performance
• Can cause numerical instability in linear models
• Makes feature importance interpretation difficult
• Increases computational cost

STRATEGIES:
• Remove one correlated feature
• Combine features (e.g., accessibility_score = 0.5*TAX + 0.5*RAD)
• Use regularization (Ridge/Lasso)
• Apply PCA to reduce dimensions

THRESHOLD: Generally consider |correlation| > 0.8 as high"
What is the main purpose of applying PCA before visualization?,"PCA reduces high-dimensional data to 2D or 3D while preserving maximum variance, enabling visualization of patterns and clusters",,Assignment 1 - PCA,PCA dimensionality-reduction visualization,,"Human brain can only visualize up to 3 dimensions effectively. PCA finds the 'best camera angles' to capture the most important patterns in high-dimensional data.

WHAT'S PRESERVED:
• Relative distances between points (approximately)
• Cluster structures and separability
• Major variance patterns

WHAT'S LOST:
• Exact feature interpretability
• Some detailed variance (minor components)",,,,
How does K-means algorithm work using the EM framework?,E-step: Assign points to nearest centroids. M-step: Update centroids as mean of assigned points. Repeat until convergence,\[\text{E-step: } c_i = \arg\min_k ||x_i - \mu_k||^2\]\[\text{M-step: } \mu_k = \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i\],Assignment 1 - K-means,k-means clustering EM-algorithm unsupervised-learning,"Like organizing people at a party - people move to closest conversation group (E-step), then each group's center shifts to balance the conversation (M-step).

PRACTICAL IMPLEMENTATION:
1. Initialize k random centroids
2. E-step: Calculate distances, assign points to nearest centroid
3. M-step: Recalculate centroids as mean of assigned points
4. Check convergence: if centroids barely moved, stop
5. Otherwise repeat steps 2-4",,,,,
What is clustering purity and how is it calculated?,Purity measures cluster homogeneity by calculating the percentage of points in each cluster that belong to the most common true class,\[\text{Purity} = \frac{1}{N} \sum_{k=1}^{K} \max_j |C_k \cap T_j|\],Assignment 1 - Clustering Evaluation,clustering evaluation purity unsupervised-learning,,"'How pure are my clusters?' - if a cluster contains mostly one type of flower, it has high purity.

COMPUTATION STEPS:
1. For each cluster, count how many points belong to each true class
2. Take the maximum count (dominant class) for each cluster
3. Sum these maxima across all clusters
4. Divide by total number of points

EXAMPLE FROM ASSIGNMENT:
• Cluster 0: 92.3% purity (mostly Setosa)
• Cluster 1: 77.0% purity (mixed Versicolor/Virginica)
• Cluster 2: 100% purity (pure Setosa)
• Overall: 88.7% purity",,,,
Why did K-means struggle to separate Versicolor and Virginica iris species?,"K-means assumes spherical clusters, but Versicolor and Virginica have overlapping, elongated distributions that violate this assumption",,Assignment 1 - K-means Limitations,k-means limitations clustering iris-dataset,,,,,,"ALGORITHMIC LIMITATION: K-means uses Euclidean distance and assumes clusters are roughly circular/spherical with similar sizes.

IRIS DATA CHARACTERISTICS:
• Setosa: Well-separated, compact cluster (easy for K-means)
• Versicolor & Virginica: Overlapping feature ranges, elongated distributions

WHY K-MEANS FAILS:
• Overlapping data: No clear separation boundary
• Non-spherical shapes: Algorithm forces circular decision boundaries
• Similar within-cluster variance assumption violated

RESULT: Perfect clustering of Setosa (100% purity), mixed results for other species (77% purity)

BETTER ALGORITHMS FOR THIS DATA:
• Gaussian Mixture Models (handles elongated clusters)
• Hierarchical clustering
• DBSCAN (density-based)"
What is the relationship between PCA's first principal component and the covariance matrix?,The first principal component is the eigenvector of the covariance matrix corresponding to the largest eigenvalue,\[Cov(X) \cdot v_1 = \lambda_1 \cdot v_1\],Assignment 2 - PCA Theory,PCA eigenvector covariance-matrix dimensionality-reduction,,,,,,Think of eigenvectors as the 'natural directions' of data spread. The eigenvector with the largest eigenvalue captures the direction of maximum variance - like finding the main axis of a stretched rubber band. This mathematical relationship ensures PCA finds the optimal low-dimensional representation that preserves the most information about data variability.
What do eigenvalues represent in PCA and how do you use them for component selection?,"Eigenvalues represent the amount of variance explained by each principal component. Select components by calculating cumulative variance percentage until reaching desired threshold (e.g., 70%)",\[\text{Variance Explained} = \frac{\lambda_i}{\sum_{j=1}^{n} \lambda_j} \times 100\%\],Assignment 2 - PCA Component Selection,PCA eigenvalues variance-explained component-selection,,,,,,"Eigenvalues are like importance scores for each direction of data spread. Larger eigenvalues mean more important directions. In practice, you rank eigenvalues from largest to smallest, then add up their percentages until you hit your target (70%, 80%, 95%). This is the 'elbow method' for dimensionality reduction - keeping just enough components to capture most of the data's story while discarding noise."
How do you initialize cluster centers in K-means and why does initialization matter?,"Common methods: random selection, k-means++, or domain knowledge. Initialization matters because K-means can converge to local optima, leading to poor clustering results",,Assignment 2 - K-means Initialization,k-means clustering initialization local-optima,,,,,,"Think of K-means initialization like choosing starting points for a treasure hunt - bad starting points can lead you to the wrong treasure. Random initialization is simple but risky. K-means++ is smarter: it chooses centers far apart from each other, like spreading scouts across a map. Poor initialization can trap the algorithm in local optima (finding a small hill instead of the mountain). That's why many implementations run K-means multiple times with different initializations and pick the best result."
What is the K-means algorithm's step-by-step process?,1) Initialize k cluster centers 2) Assign each point to nearest center 3) Update centers to cluster centroids 4) Repeat steps 2-3 until convergence (centers stop moving significantly),\[\mu_j = \frac{1}{|C_j|} \sum_{x_i \in C_j} x_i\],Assignment 2 - K-means Algorithm,k-means clustering algorithm centroid-update,,,,,,K-means is like organizing people into groups at a party. Start with k party hosts (centers) in random locations. Each guest (data point) joins the nearest host. Then hosts move to the center of their groups (centroid). Repeat until hosts stop moving much. The algorithm minimizes within-cluster distances - everyone wants to be close to their group's center. Convergence happens when the 'social groups' stabilize and no one wants to switch teams anymore.
What is the Dunn Index and what does a higher value indicate?,"Dunn Index = minimum inter-cluster distance / maximum intra-cluster distance. Higher values indicate better clustering with well-separated, compact clusters","\[\text{Dunn Index} = \frac{\min_{i \neq j} d(C_i, C_j)}{\max_k \Delta(C_k)}\]",Assignment 2 - Clustering Evaluation,dunn-index clustering-evaluation inter-cluster intra-cluster,,,,,,"The Dunn Index is like measuring the quality of city neighborhoods. You want neighborhoods (clusters) to be tight-knit internally (small intra-cluster distance) but well-separated from each other (large inter-cluster distance). A high Dunn Index means clear boundaries between groups - like distinct neighborhoods with their own character. However, it's sensitive to outliers (one bad neighbor can ruin the score) and computationally expensive for large datasets."
What are the main limitations of the Dunn Index for clustering evaluation?,1) Sensitive to outliers and noise 2) Computationally expensive (O(n²)) 3) May not work well with non-spherical clusters 4) Single outlier can dramatically reduce the index,,Assignment 2 - Clustering Evaluation Limitations,dunn-index limitations clustering-evaluation outliers,,,,,,"The Dunn Index is like judging a school by its worst student and best class - not always fair! A single outlier can make the minimum inter-cluster distance tiny, ruining the score even if most clusters are well-separated. It assumes clusters are round (spherical), so it struggles with chain-like or irregular shaped clusters. For large datasets, computing all pairwise distances becomes prohibitively slow. Alternative metrics like Silhouette coefficient or Calinski-Harabasz index often provide more robust evaluations."
"How does PCA projection reveal patterns in data, and what do projected values represent?","PCA projection transforms data into principal component space. Projected values represent data points' coordinates along the new axes, revealing the main patterns of variation",\[y = X \cdot v\],Assignment 2 - PCA Interpretation,PCA projection data-patterns interpretation,,,,,,"PCA projection is like rotating a photograph to get the best view. Imagine photographing a group of people from the side - you lose depth information but capture height differences clearly. Similarly, PCA finds the 'best angles' (principal components) to view your data. The projected values tell you where each data point sits along these optimal directions. In the study hours example, the first component might represent 'overall study intensity' - students with high projected values are generally more studious across all activities."
When should you prefer PCA over other dimensionality reduction techniques?,Use PCA when: 1) Data has linear relationships 2) You need interpretable components 3) Preserving variance is important 4) You want to remove noise while keeping signal,,Assignment 2 - PCA Applications,PCA applications dimensionality-reduction linear-relationships,,,,,,"PCA is like a Swiss Army knife for dimensionality reduction - versatile but not always the best tool. It excels when relationships between variables are linear (like height and weight correlating). It's interpretable: you can understand what each component represents. Perfect for removing noise while keeping important signals, like cleaning up audio recordings. However, avoid PCA for non-linear relationships (use kernel PCA or autoencoders instead) or when you need to preserve specific features rather than combinations of features."
What is the Normal Matrix in linear regression and what are its key mathematical properties?,The Normal Matrix is X^T X that appears in the linear regression solution. It is symmetric and positive semi-definite.,\[\text{Normal Matrix} = X^T X \in \mathbb{R}^{d \times d}\],Assignment 3 - Normal Matrix Properties,linear-regression normal-matrix matrix-properties,,,,,,"Think of it as the 'fingerprint' of your data's structure. Symmetric means it's balanced around its diagonal (like a mirror). Positive semi-definite means all eigenvalues ≥ 0, indicating the data doesn't contradict itself. This matrix encodes how features correlate with each other - crucial for understanding if your regression problem is well-posed."
When does linear regression have a unique solution?,"When the Normal Matrix X^T X is positive definite (all eigenvalues > 0), which requires linearly independent columns in X.",\[\hat{w} = (X^T X)^{-1} X^T y \text{ exists uniquely when } X^T X \text{ is invertible}\],Assignment 3 - Unique Solutions,linear-regression uniqueness invertibility,"Imagine trying to find the intersection of lines. If features are linearly dependent, it's like having parallel lines - no unique intersection. Independent features give you lines that meet at exactly one point. In ML terms: you need more training examples than features (n > d) and no redundant features for a unique solution.",,,,,
What are feature maps and how do they extend linear regression capabilities?,"Feature maps Φ(X) transform input data into higher-dimensional space, allowing linear models to capture non-linear patterns.","\[\Phi: \mathbb{R}^d \to \mathbb{R}^D, \quad \hat{y} = \Phi(X)w\]",Assignment 3 - Feature Maps,feature-maps non-linear-regression polynomial-features,,make data linearly separable in a higher dimension rather than wrestling with non-linearity directly.,,,,
How do polynomial features work and what's the trade-off with degree?,"Polynomial features create powers of input: [x, x², x³, ...]. Higher degrees fit training data better but risk overfitting.","\[\Phi_{poly}(x) = [1, x, x^2, x^3, \ldots, x^d]\]",Assignment 3 - Polynomial Features,polynomial-features overfitting model-complexity,,,,,,"Think of polynomial degree as 'flexibility knob'. Low degree = rigid ruler (underfitting), high degree = bendy snake (overfitting). Degree 1 fits lines, degree 2 parabolas, degree 3 S-curves. The sweet spot balances expressiveness with generalization. Watch training vs validation error: when they diverge, you've gone too far."
What are Radial Basis Function (RBF) features and when are they useful?,"RBF features create localized 'bumps' centered at specific positions, useful for capturing local patterns in data.",\[\Phi_{RBF}(x) = \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)\],Assignment 3 - RBF Features,rbf-features gaussian-basis local-features,,,,,,"Imagine placing 'hills' of influence at key data points. Each RBF is like a spotlight with Gaussian falloff - bright at center, dim at edges. Scale σ controls width: small σ = sharp peaks (local fit), large σ = broad hills (smooth fit). Perfect for data with local structure, like modeling city temperatures where nearby locations are similar."
What computational challenges arise with high-dimensional linear regression?,"Memory requirements grow quadratically (O(d²)) for storing X^T X, making matrix inversion computationally prohibitive.",\[\text{Memory for } X^T X = d^2 \times 4 \text{ bytes (float32)}\],Assignment 3 - Computational Challenges,computational-complexity memory-requirements high-dimensional,,,,,,"Real example: 512×512×3 images = 786,432 features. X^T X needs 2.3 TB memory! Even supercomputers struggle. Solutions: (1) Gradient descent avoids computing X^T X, (2) Dimensionality reduction via PCA, (3) Regularization prevents overfitting, (4) Online learning processes data in chunks. The curse of dimensionality is real - plan accordingly."
How do piecewise features work and what patterns do they capture?,"Piecewise features divide input space into regions. Constant creates step functions, linear creates connected line segments.",\[\Phi_{piece}(x) = \begin{cases} 1 & \text{if } a \leq x \leq b \\ 0 & \text{otherwise} \end{cases}\],Assignment 3 - Piecewise Features,piecewise-features step-functions local-models,,,,,,"Think of building a staircase approximation to curved data. Piecewise constant = stairs with flat steps, piecewise linear = connecting the steps with ramps. Great for data with distinct regimes (like different price brackets) or when you suspect the relationship changes at certain thresholds. Each piece models a local linear relationship."
What is RMSE and why is it important for regression evaluation?,Root Mean Square Error measures average prediction error in original units. Lower RMSE indicates better model performance.,\[RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}\],Assignment 3 - Model Evaluation,rmse evaluation-metrics regression-performance,,,,,,"RMSE is like a 'average wrongness' meter in original units. If predicting house prices, RMSE = $10k means you're typically off by $10k. It penalizes large errors more than small ones (squared term), so it's sensitive to outliers. Compare training vs test RMSE: similar values = good generalization, large gap = overfitting. Target: RMSE < 4.0 for Boston housing is a solid benchmark."
What is the closed-form solution for Ridge Regression and how does it differ from ordinary linear regression?,"Ridge regression solution: w* = (X^T X + λI)^(-1) X^T y. The key difference is adding λI (lambda times identity matrix) to X^T X, which ensures the matrix is invertible even when X^T X is singular.",\[w^* = (X^T X + \lambda I)^{-1} X^T y\],Assignment 4 - Ridge Regression,ridge-regression regularization linear-algebra,,,,,,"The λ parameter controls regularization strength. Higher λ = more regularization = simpler model. This prevents overfitting by penalizing large coefficients. Unlike OLS which can fail when features > samples, ridge regression always has a solution due to the λI term making the matrix invertible."
Why does Ridge Regression use the L2 penalty term λ||w||₂² and what effect does it have on model coefficients?,"The L2 penalty shrinks coefficients toward zero, preventing overfitting. It encourages smaller, more stable coefficients while keeping all features in the model (unlike L1 which can zero out features).",\[L = ||Xw - y||_2^2 + \lambda ||w||_2^2\],Assignment 4 - Ridge Regression,regularization l2-penalty overfitting,,,,,,"Think of regularization as a 'simplicity tax' - the model pays a penalty for complexity. L2 penalty creates a circular constraint in parameter space, leading to smooth coefficient shrinkage. This is especially valuable when you have multicollinearity (correlated features) as it distributes weights more evenly across related features."
"What is the fundamental difference between covariance and correlation matrices, and when should each be used in PCA?",Covariance measures actual variance relationships but is scale-dependent. Correlation is standardized covariance (scale-independent). Use correlation matrix for PCA when features have different units/scales; use covariance when features are in same units.,"\[\text{Correlation} = \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y}\]",Assignment 4 - Correlation vs Covariance,pca covariance correlation standardization,,,,,,"Correlation matrix PCA is equivalent to standardizing data first, then applying covariance-based PCA. Without standardization, features with larger scales dominate the principal components. Example: If you have height (cm) and weight (kg), height's larger scale would dominate PC1 without correlation-based PCA."
How does changing the scale/units of a single feature affect PCA results when using covariance vs correlation matrices?,Covariance-based PCA: Dramatically changes results as the rescaled feature may dominate principal components. Correlation-based PCA: No change in results as correlation standardizes all features to unit variance.,\[\text{Standardized } X_i = \frac{X_i - \mu_i}{\sigma_i}\],Assignment 4 - Scale Sensitivity,pca standardization scale-invariance preprocessing,,,,,,"This is why preprocessing matters! If you change TAX from 'per $10,000' to 'per $1', covariance-based PCA completely changes because TAX now has 10,000x larger variance. Correlation-based PCA treats all features equally regardless of their original scales, making it more robust for mixed-unit datasets."
"What are the minimum and maximum possible F1-scores, and what types of classifiers achieve these extremes?",Minimum F1 = 0 (achieved by classifier that never predicts positive class or has no correct positive predictions). Maximum F1 = 1 (achieved by perfect classifier with no false positives or false negatives).,\[F_1 = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}\],Assignment 4 - F1 Score,f1-score precision recall classification-metrics,,,,,,"F1 = 0 examples: Always predict negative, or always predict positive when no positive cases exist. F1 = 1 means perfect precision AND recall simultaneously. F1 is the harmonic mean of precision and recall, so it's only high when both are high - this makes it useful for balanced evaluation of classification performance."
"In safety-critical applications (fire detection, mushroom identification), which confusion matrix characteristic should you prioritize and why?","Minimize False Negatives (maximize Recall) even at the cost of False Positives. Missing a fire or poisonous mushroom has catastrophic consequences, while false alarms are just inconvenient.",\[\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\],Assignment 4 - Safety-Critical Classification,recall safety-critical false-negatives risk-assessment,,,,,,This reflects the asymmetric cost of errors. Fire detection: False alarm = evacuation inconvenience; missed fire = potential deaths. Mushroom classification: False positive = skip edible mushroom; false negative = eat poison mushroom. Always consider the real-world consequences of each error type when choosing metrics and thresholds.
What's the difference between micro-averaging and macro-averaging for F1-scores in multi-class classification?,"Micro-averaging: Calculate metrics globally by counting total TP, FP, FN across all classes. Macro-averaging: Calculate metrics for each class separately, then average them. Micro-averaging favors frequent classes; macro-averaging treats all classes equally.",\[\text{Micro-F1} = \frac{2 \sum TP}{2\sum TP + \sum FP + \sum FN}\],Assignment 4 - Multi-class Metrics,multiclass f1-score micro-averaging macro-averaging,,,,,,"Choose based on your goal: Micro-averaging if you care about overall accuracy across all predictions (class frequency matters). Macro-averaging if you want to treat rare and common classes equally (useful for imbalanced datasets). In practice, macro-averaging often reveals problems with minority class performance that micro-averaging might hide."
What does the Woodbury Matrix Identity allow us to do in the context of Ridge Regression computational complexity?,"It provides an alternative way to compute (X^T X + λI)^(-1) that can be more efficient when n < d. Instead of inverting a d×d matrix, we can invert smaller n×n matrices, reducing complexity from O(d³) to O(n³) when beneficial.",\[(A + UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1}VA^{-1}\],Assignment 4 - Computational Complexity,woodbury-identity computational-complexity matrix-inversion,,,,,,"This is crucial for high-dimensional data (d >> n). Standard approach: invert d×d matrix in O(d³) time. Woodbury approach: work with n×n matrices in O(n³) time. When d=10,000 and n=1,000, this is a 1000x speedup! The identity essentially lets you 'push' the inversion to the smaller dimensional space."
What is the fundamental independence assumption of Naïve Bayes classifiers?,Features are conditionally independent given the class label,"\[P(X_1, X_2, ..., X_n | C) = \prod_{i=1}^{n} P(X_i | C)\]",Assignment 5 - Naïve Bayes Theory,naive-bayes independence conditional-independence,,,,,,"This means that knowing the value of one feature doesn't provide information about another feature, once we know the class. Like medical symptoms: given a disease diagnosis, fever doesn't tell us about cough likelihood. This assumption is 'naïve' because features are often correlated in reality, but the classifier works surprisingly well despite this simplification. Violations of this assumption can lead to overconfident predictions and bias errors."
How does parameter complexity scale for joint likelihood tables vs. Naïve Bayes?,"Joint tables: exponential (2^n parameters), Naïve Bayes: linear (2n parameters) for binary features",\[\text{Joint: } 2^n \text{ vs. NB: } 2n \text{ parameters}\],Assignment 5 - Complexity Analysis,naive-bayes complexity scalability parameters,,,,,,"This is why Naïve Bayes is practical for high-dimensional data. For 10 binary features: joint table needs 1024 parameters, Naïve Bayes only 20. The independence assumption trades modeling accuracy for computational efficiency and sample complexity. With limited training data, the parameter reduction often leads to better generalization despite the modeling bias."
What is Laplace smoothing and why is it essential for Naïve Bayes?,Add α (usually 1) to all counts to prevent zero probabilities for unseen feature-class combinations,"\[P(X_i = v | C = c) = \frac{\text{count}(X_i = v, C = c) + \alpha}{\text{count}(C = c) + \alpha |V_i|}\]",Assignment 5 - Flu Detection,laplace-smoothing naive-bayes zero-probability,,,,,,"Without smoothing, if a feature value never appears with a class in training data, P(feature|class) = 0, making the entire prediction zero due to multiplication. This is catastrophic for new data. Laplace smoothing ensures all probabilities are non-zero. Think of it as assuming we've seen each combination at least once. The parameter α controls smoothing strength: α=1 is standard, larger α means more uniform distribution."
How does Gaussian Naïve Bayes handle continuous features?,"Assumes each feature follows a Gaussian distribution within each class, estimated by sample mean and variance",\[P(X_i = x | C = c) = \frac{1}{\sqrt{2\pi\sigma_{ic}^2}} \exp\left(-\frac{(x - \mu_{ic})^2}{2\sigma_{ic}^2}\right)\],Assignment 5 - Gaussian Implementation,gaussian-naive-bayes continuous-features probability-density,,,,,,"For each class c and feature i, we estimate μ_ic (mean) and σ²_ic (variance) from training data. During prediction, we evaluate the Gaussian PDF at the test point. This extends Naïve Bayes beyond categorical data to real-valued features like temperature, height, or medical measurements. The Gaussian assumption may not hold in practice, but often works well. Standardization often improves performance."
When does the conditional independence assumption of Naïve Bayes lead to high bias?,"When features are strongly correlated within classes, creating dependency that violates the independence assumption",\[\text{Bias occurs when: } X_1 \not\perp X_2 | C\],Assignment 5 - Independence Analysis,naive-bayes bias independence-violation correlation,,,,,"predicting age from blood pressure and cholesterol. These are positively correlated within each age group, violating independence. Naïve Bayes will overweight evidence when both are high/low together. Hospital admission example: diabetes and gallbladder disease appear independent overall, but given hospitalization, they become negatively correlated (if one is absent, the other is more likely present to explain admission).",
How do you compute posterior probabilities in Naïve Bayes classification?,Use Bayes' theorem with class priors and the product of feature likelihoods,"\[P(C | X_1, ..., X_n) = \frac{P(C) \prod_{i=1}^n P(X_i | C)}{P(X_1, ..., X_n)}\]",Assignment 5 - Bayes Classification,bayes-theorem posterior-probability classification,,,,,,"Step-by-step: (1) Calculate class priors P(C) from training data, (2) Calculate feature likelihoods P(X_i|C) for each feature-class pair, (3) Multiply prior by all feature likelihoods, (4) Normalize by evidence (or just compare unnormalized values). The denominator P(X) is often ignored for classification since it's the same for all classes. Use log-probabilities to avoid numerical underflow with many features."
What is the relationship between marginal and conditional independence?,"Neither direction holds in general: X₁ ⊥ X₂ does not imply X₁ ⊥ X₂|C, and X₁ ⊥ X₂|C does not imply X₁ ⊥ X₂",\[X_1 \perp X_2 \not\Rightarrow X_1 \perp X_2 | C \text{ and } X_1 \perp X_2 | C \not\Rightarrow X_1 \perp X_2\],Assignment 5 - Independence Theory,independence conditional-independence marginal-independence,,,,,,"Counterexample 1: ABO blood type and personality traits are independent overall (marginal), but may show association within sexes (conditional dependence). Counterexample 2: Fever and headache are conditionally independent given flu status (both caused directly by flu), but marginally dependent (often co-occur during flu season). This subtlety is crucial for understanding when Naïve Bayes assumptions are violated."
How does missing data affect Naïve Bayes classification?,Simply omit the missing features from the likelihood calculation - the independence assumption makes this straightforward,\[P(C | X_{observed}) \propto P(C) \prod_{i \in observed} P(X_i | C)\],Assignment 5 - Missing Data Handling,missing-data naive-bayes robustness,,,,,,"This is a major advantage of Naïve Bayes over many other classifiers. When a thermometer fails (missing temperature), we just exclude temperature from the calculation and use remaining features (fever, cough). The independence assumption means missing features don't affect the relationships between observed features. However, this changes the relative importance of features - fewer features means each remaining one has more weight in the decision."
What is the softmax function and why is it used in multiclass logistic regression?,The softmax function converts raw logits into normalized class probabilities that sum to 1,\[\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}\],Assignment 6 - Logistic Regression,logistic-regression softmax multiclass probability,,,,,,"Think of softmax as a 'soft' version of argmax - it assigns the highest probability to the largest logit but gives non-zero probabilities to all classes. Unlike sigmoid (binary), softmax handles multiple classes naturally. The exponential ensures positive values, and normalization ensures probabilities sum to 1. Essential for multiclass classification where you need interpretable probability distributions."
What is the Bayes decision rule for optimal classification?,Assign observation x to class with highest posterior probability: argmax P(class|x),\[\hat{y} = \arg\max_k P(C_k|\mathbf{x}) = \arg\max_k P(\mathbf{x}|C_k)P(C_k)\],Assignment 6 - Bayes Error,bayes-rule optimal-classifier decision-theory,,,,,,"The Bayes classifier is theoretically optimal - no other classifier can achieve lower error rate. It's like having perfect knowledge of the true data distribution. In practice, we estimate these probabilities from data. The decision boundary occurs where P(C_1|x) = P(C_2|x). This connects to likelihood ratios and provides the gold standard for comparing other classifiers."
What is the Bayes error and what does it represent?,The minimum possible classification error rate achieved by the optimal Bayes classifier,"\[\epsilon_{Bayes} = \int 1 - \max_k P(C_k|\mathbf{x}) \, d\mathbf{x}\]",Assignment 6 - Bayes Error,bayes-error optimal-performance theoretical-limit,,,,,,"Think of Bayes error as the 'speed of light' for classification - a fundamental limit you cannot exceed. It represents irreducible error due to overlapping class distributions. High Bayes error means classes are inherently hard to separate (like distinguishing identical twins), while low Bayes error means clear class separation exists. Any classifier with error significantly above Bayes error has room for improvement."
How does cross-entropy loss work in logistic regression and why is it preferred over MSE?,"Cross-entropy measures difference between predicted and true probability distributions, providing better gradients for classification",\[L = -\sum_{i=1}^{n} \sum_{k=1}^{K} y_{ik} \log(\hat{p}_{ik})\],Assignment 6 - Logistic Regression,cross-entropy loss-function classification optimization,,,,,,"Cross-entropy is like asking 'how surprised am I by the true answer given my predictions?' Perfect predictions give zero loss, while confident wrong predictions give huge penalties. Unlike MSE, cross-entropy provides strong gradients even when predictions are very wrong, leading to faster convergence. MSE can cause gradient saturation in classification, making training slow when the model needs to learn most."
Why is linear regression generally unsuitable for classification tasks?,"Linear regression outputs unbounded continuous values, lacks probabilistic interpretation, and uses inappropriate loss function (MSE) for discrete targets",\[\text{Linear: } \hat{y} = \mathbf{w}^T\mathbf{x} + b \text{ (unbounded)}\],Assignment 6 - Linear vs Logistic,linear-regression classification limitations model-choice,,,,,,"Imagine using a thermometer to measure personality types - wrong tool for the job! Linear regression treats class labels as continuous numbers (0,1,2) implying Class 2 is 'twice' Class 1, which is meaningless. Outputs can be negative or >1, making probability interpretation impossible. MSE loss doesn't penalize confident wrong classifications appropriately. Decision boundaries become linear hyperplanes rather than probability-based regions."
How do class priors affect the Bayes decision boundary?,"Higher prior probability shifts decision boundary toward the less likely class, reducing its decision region",\[P(C_k|\mathbf{x}) \propto P(\mathbf{x}|C_k)P(C_k)\],Assignment 6 - Bayes Error,class-priors decision-boundary bayes-rule,,,,,,"Think of priors as 'voting weights' - if one class is much more common, you need stronger evidence to predict the rare class. Like a medical test: if a disease is rare (low prior), you need very strong symptoms to diagnose it. Mathematically, increasing P(B) makes the decision boundary shift away from Class B's center, shrinking B's decision region. This reflects real-world asymmetric costs and frequencies."
What happens to decision boundaries when classes have different covariance matrices in Gaussian classification?,Decision boundaries become non-linear (quadratic) curves instead of straight lines,"\[\Sigma_A = I, \Sigma_B = 2I \Rightarrow \text{quadratic boundary}\]",Assignment 6 - Bayes Error,gaussian-classification covariance decision-boundary quadratic,,,,,,"Equal covariances create linear boundaries (like parallel parking spaces), but different covariances create curved boundaries (like parking around a circular building). When one class is more 'spread out' (higher variance), its influence extends further but with lower density. The math involves quadratic terms from the Mahalanobis distance, creating elliptical or hyperbolic decision regions rather than straight lines."
How does gradient descent work in logistic regression training?,Iteratively updates weights by moving in direction of negative gradient to minimize cross-entropy loss,\[\mathbf{w} \leftarrow \mathbf{w} - \alpha \nabla L(\mathbf{w})\],Assignment 6 - Logistic Regression,gradient-descent optimization training logistic-regression,,,,,,"Imagine rolling a ball down a hill to find the bottom - gradient descent follows the steepest downward slope at each step. The gradient points toward steepest increase, so negative gradient points toward steepest decrease in loss. Learning rate α controls step size: too large causes overshooting, too small causes slow convergence. Unlike linear regression (closed-form solution), logistic regression requires iterative optimization due to non-linear sigmoid/softmax functions."
What is information gain in decision trees and how is it calculated?,Information gain measures how much a feature reduces uncertainty (entropy) when splitting data. It's the difference between parent entropy and weighted average of children entropies.,"\[IG(S,A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)\]",Assignment 7 - Decision Tree Splitting,decision-trees information-gain entropy splitting-criteria,,,,,,"Think of information gain like organizing a messy room - each split should create more organized (less random) groups. Higher information gain means better splits. In the mushroom example, the optimal first split maximizes this measure. Normalized information gain adjusts for bias toward features with more possible values, ensuring fair comparison between different attributes."
What is entropy in decision trees and what does it measure?,"Entropy measures the impurity or randomness in a dataset. Pure nodes (all same class) have entropy 0, while maximally mixed nodes approach entropy 1.",\[H(S) = -\sum_{i=1}^{c} p_i \log_2(p_i)\],Assignment 7 - Impurity Measures,decision-trees entropy impurity-measure information-theory,,,,,,"Entropy is like measuring chaos in a group. A classroom with all students paying attention (pure) has low entropy, while a classroom with half sleeping, half talking has high entropy. Decision trees aim to create pure leaf nodes by reducing entropy at each split. Alternative measures include Gini impurity, but entropy connects directly to information theory and provides intuitive logarithmic scaling."
How do you adapt decision trees from classification to regression problems?,"Change the splitting criterion from entropy/Gini to variance reduction, use mean (not mode) for leaf predictions, and employ MSE or MAE for evaluation instead of accuracy.",\[Variance = \frac{1}{n}\sum_{i=1}^{n}(y_i - \bar{y})^2\],Assignment 7 - Regression Trees,decision-trees regression classification adaptation variance-reduction,,,,,,"Converting trees for regression is like changing from sorting colored balls (discrete categories) to organizing balls by weight (continuous values). Instead of asking 'which class appears most?', we ask 'what's the average value?'. Variance replaces entropy as our measure of impurity - high variance means the values in a node are spread out, low variance means they're similar. This makes regression trees powerful for predicting house prices, temperatures, or any continuous target."
What are the key hyperparameters for tuning decision tree performance?,"Max depth (tree height), max leaf nodes (terminal node count), min samples split (samples needed to split), and criterion (gini vs entropy for measuring split quality).",,Assignment 7 - Hyperparameter Tuning,decision-trees hyperparameters overfitting model-selection cross-validation,,,,,,"Hyperparameter tuning is like adjusting the rules for growing a tree. Max depth prevents the tree from becoming too tall and overfitting (like pruning). Min samples split ensures splits are statistically meaningful (don't split on tiny groups). Max leaf nodes controls overall complexity. The criterion choice (gini vs entropy) affects splitting decisions - gini is faster to compute, entropy connects to information theory. Use cross-validation to find the sweet spot between underfitting and overfitting."
What is the difference between Gini impurity and Entropy as splitting criteria?,"Both measure node impurity, but Gini uses squared probabilities while Entropy uses logarithms. Gini is computationally faster; Entropy connects to information theory and tends to create more balanced trees.",\[Gini = 1 - \sum_{i=1}^{c} p_i^2\] vs \[Entropy = -\sum_{i=1}^{c} p_i \log_2(p_i)\],Assignment 7 - Splitting Criteria,decision-trees gini-impurity entropy splitting-criteria impurity-measures,,,,,,"Choosing between Gini and Entropy is like choosing between two different ways to measure messiness. Gini is like counting mismatched pairs - faster but less precise. Entropy is like measuring information content - slower but more theoretically grounded. In practice, they often give similar results, but Entropy tends to produce more balanced splits and is preferred when you want to maximize information gain. Gini is default in many implementations due to computational efficiency."
How do you prevent overfitting in decision trees during training?,"Control tree complexity through pre-pruning (max depth, min samples split, max leaf nodes) or post-pruning, and use cross-validation to select optimal hyperparameters.",,Assignment 7 - Overfitting Prevention,decision-trees overfitting pruning regularization cross-validation,,,,,,"Preventing overfitting is like teaching someone to generalize rather than memorize. An overfitted tree is like a student who memorizes answers but can't handle new questions. Pre-pruning sets growth limits during training (like setting study guidelines), while post-pruning removes branches after growing (like editing an essay). Cross-validation helps find the right balance - too simple and you underfit (poor performance), too complex and you overfit (good training, poor testing). The goal is a tree that captures true patterns, not noise."
What evaluation metrics should you use for decision tree classification and why?,"Use precision (correct positive predictions), recall (finding all positives), F1-score (harmonic mean of precision/recall), and confusion matrix for comprehensive performance assessment.","\[Precision = \frac{TP}{TP + FP}\], \[Recall = \frac{TP}{TP + FN}\], \[F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}\]",Assignment 7 - Model Evaluation,decision-trees evaluation-metrics precision recall f1-score classification-performance,,,,,,"Evaluation metrics tell the complete story of your model's performance. Accuracy alone can be misleading with imbalanced datasets (like the Titanic where more people died than survived). Precision answers 'Of those I predicted would survive, how many actually did?' Recall answers 'Of those who actually survived, how many did I find?' F1-score balances both when you need a single metric. Think of medical diagnosis: high precision means few false alarms, high recall means catching all sick patients. Use confusion matrix to see exactly where your tree makes mistakes."
What is the variance formula for Random Forest predictor and what does it tell us about ensemble benefits?,"Random Forest variance = (ρ + (1-ρ)/B) × σ², where ρ is tree correlation, B is number of trees, σ² is individual tree variance",\[\text{Var}(\hat{f}_B) = \left(\rho + \frac{1-\rho}{B}\right)\sigma^2\],Assignment 8 - Random Forest Theory,random-forest variance ensemble correlation,,,,,,"This formula reveals why ensembles work: as B increases, variance decreases toward ρσ². The correlation term ρ represents the fundamental limit - even infinite trees can't reduce variance below ρσ². This explains why Random Forest uses feature randomization to decorrelate trees (reduce ρ), making the ensemble more effective than simple bagging."
How does Random Forest reduce correlation between trees and why is this crucial?,"Random Forest selects random subset of features at each split, decorrelating trees by preventing dominant features from being used consistently across all trees",,Assignment 8 - Random Forest,random-forest decorrelation feature-selection ensemble,,,,,,"Think of it like asking different experts who each specialize in different areas. If all experts focus on the same information (high correlation), their combined opinion isn't much better than one expert. But if each expert considers different aspects (low correlation), their combined wisdom is much more reliable. Random Forest achieves this by randomly restricting which features each tree can consider at each split."
What is a decision stump and why is it the preferred weak learner for AdaBoost?,"A decision stump is a decision tree with maximum depth 1 (single split). It's ideal for AdaBoost because it's simple, fast to train, and provides the 'weak learning' property",,Assignment 8 - AdaBoost,adaboost decision-stump weak-learner boosting,,,,,,"Decision stumps are intentionally simple - they make decisions based on just one feature and one threshold. This simplicity is actually a strength in AdaBoost because: (1) they train quickly on reweighted data, (2) they rarely overfit, (3) they provide diverse perspectives when combined, and (4) they satisfy the weak learning assumption (slightly better than random guessing). Complex trees would defeat the purpose of iterative improvement."
How does AdaBoost calculate the weight α_m for each weak learner and what does it represent?,"α_m = (1/2) × ln((1-ε_m)/ε_m), where ε_m is the weighted error rate. Higher α means more influence in final ensemble",\[\alpha_m = \frac{1}{2}\ln\left(\frac{1-\varepsilon_m}{\varepsilon_m}\right)\],Assignment 8 - AdaBoost,adaboost alpha-weight ensemble weighted-voting,,,,,,"This formula ensures that better classifiers get exponentially more influence. When error ε→0, α→∞ (perfect classifier dominates). When ε=0.5 (random guessing), α=0 (no influence). When ε>0.5, α<0 (classifier is worse than random, so we flip its predictions). This creates a natural quality-based voting system where good classifiers have strong voices and bad ones are ignored or reversed."
How does AdaBoost update sample weights and why does this improve learning?,"Weights are updated as w_i^(m+1) = w_i^(m) × exp(-α_m × y_i × G_m(x_i)). Misclassified samples get increased weights, correctly classified get decreased weights",\[w_i^{(m+1)} = w_i^{(m)} \cdot \exp(-\alpha_m y_i G_m(x_i))\],Assignment 8 - AdaBoost,adaboost weight-update adaptive-learning sequential,,,,,,"This is like a teacher focusing more attention on struggling students. When y_i × G_m(x_i) > 0 (correct prediction), the weight decreases. When y_i × G_m(x_i) < 0 (incorrect prediction), the weight increases exponentially. This forces the next weak learner to focus on the 'hard' examples that previous learners got wrong, creating a sequential learning process where each classifier specializes in different challenging cases."
What is the key difference between Random Forest (bagging) and AdaBoost (boosting) learning strategies?,"Random Forest trains trees independently in parallel on different data subsets. AdaBoost trains learners sequentially, where each focuses on mistakes of previous learners",,Assignment 8 - Ensemble Comparison,ensemble bagging boosting parallel sequential,,,,,,"Think of Random Forest as a committee of independent experts, each analyzing different evidence and voting equally. AdaBoost is like a relay team where each member fixes the mistakes of the previous one, with better performers getting stronger voices. Random Forest reduces variance through averaging, while AdaBoost reduces bias by focusing on hard cases. Random Forest is more robust to noise; AdaBoost can achieve lower training error but may overfit."
What does 'polarity' mean in the AdaBoost decision stump context and how does it affect classification?,Polarity determines which side of the threshold gets +1 label. Polarity=+1: left/below threshold → +1. Polarity=-1: left/below threshold → -1,,Assignment 8 - AdaBoost Implementation,adaboost decision-stump polarity threshold classification,,,,,,"Polarity is like choosing which way to orient a decision boundary. For a vertical line (x₁ threshold), polarity=+1 means 'left side is positive class', while polarity=-1 means 'right side is positive class'. This flexibility allows each stump to find the best orientation for separating classes. In the helper script visualization, red points are +1 class and blue points are -1 class, making it easy to see which polarity works better for each potential split."
Why might different initial stumps in AdaBoost lead to different final ensemble classifiers?,"Each initial stump creates different weight distributions, causing subsequent learners to focus on different misclassified examples, leading to distinct learning paths and decision boundaries",,Assignment 8 - AdaBoost Paths,adaboost initialization path-dependence ensemble diversity,,,,,,"AdaBoost is like a snowball effect - the first choice determines which mistakes get emphasized, which shapes what the second learner focuses on, and so on. Even if multiple stumps have the same initial error rate, they misclassify different points. This creates a butterfly effect where small initial differences lead to dramatically different final classifiers. It's why AdaBoost can find multiple valid solutions to the same problem, each with its own strengths and decision boundary characteristics."
What is the core optimization problem that SVMs solve for linearly separable data?,Minimize the norm of the weight vector while maintaining correct classification with maximum margin,"\[\min_{w,b} \frac{1}{2}||w||^2 \text{ subject to } y_i(w^T x_i + b) \geq 1 \text{ for all } i\]",Assignment 9 - SVM Optimization,svm optimization margin hyperplane,,,,,,"This formulation finds the hyperplane that maximally separates classes. The constraint ensures all points are correctly classified with at least unit margin. The squared norm minimization leads to the largest possible margin, making SVMs robust to new data. Think of it as finding the widest 'street' between two neighborhoods (classes)."
Why do only support vectors determine the SVM decision boundary?,Support vectors are the only points that lie exactly on the margin boundaries and have non-zero Lagrange multipliers (alpha > 0),"\[f(x) = \sum_{i \in SV} \alpha_i y_i K(x_i, x) + b\]",Assignment 9 - Support Vectors,support-vectors lagrange-multipliers kkt-conditions,,,,,,"In the dual formulation, points far from the boundary have alpha = 0 and don't contribute to the decision function. Only support vectors (points on or within the margin) have alpha > 0. This is like having a democracy where only the 'swing voters' (support vectors) determine the outcome - the strongly committed voters on either side don't affect the final decision boundary."
What is the kernel trick and why is it computationally advantageous?,The kernel trick allows computing inner products in high-dimensional feature spaces without explicitly mapping data to those spaces,"\[K(x, z) = \phi(x)^T \phi(z)\]",Assignment 9 - Kernel Trick,kernel-trick feature-mapping computational-efficiency,,,,,,"Instead of transforming data to high dimensions and computing dot products there, kernels compute the same result directly in the original space. For example, the RBF kernel implicitly maps to infinite dimensions but only requires computing a simple exponential function. It's like having a shortcut through a mountain instead of climbing over it - you get to the same destination much faster."
Why does the RBF kernel correspond to an infinite-dimensional feature space?,"The RBF kernel's exponential can be expanded as an infinite Taylor series, creating infinitely many feature dimensions","\[K(x,z) = e^{-\gamma||x-z||^2} = \sum_{n=0}^{\infty} \frac{(-\gamma||x-z||^2)^n}{n!}\]",Assignment 9 - RBF Kernel Theory,rbf-kernel infinite-dimensions taylor-series feature-space,,,,,,"Each term in the Taylor expansion represents a different polynomial degree, creating an infinite hierarchy of features. This allows RBF SVMs to capture arbitrarily complex decision boundaries. The gamma parameter controls the 'locality' - high gamma creates tight, local decision regions around support vectors, while low gamma creates smoother, more global boundaries."
How do different kernels handle different types of non-linear patterns?,"Linear kernels handle linearly separable data, polynomial kernels capture curved boundaries, and RBF kernels excel at complex local patterns","\[\text{Linear: } K(x,z) = x^T z \text{, Poly: } K(x,z) = (x^T z + c)^d \text{, RBF: } K(x,z) = e^{-\gamma||x-z||^2}\]",Assignment 9 - Kernel Comparison,kernel-types polynomial-kernel rbf-kernel pattern-recognition,,,,,,"Think of kernels as different 'lenses' for viewing data: linear kernel sees straight lines, polynomial kernel sees curves and bends, RBF kernel sees local bumps and valleys. XOR patterns need RBF kernels for their local decision regions, while moons might work with polynomial kernels for their curved boundaries. The choice depends on the geometric nature of your data's class separation."
What are the key differences between SVM and Logistic Regression in terms of loss function and objective?,"SVM uses hinge loss and maximizes margin, while Logistic Regression uses log-likelihood loss and maximizes probability","\[\text{SVM: } L_{hinge} = \max(0, 1-yf(x)) \text{, LogReg: } L_{log} = \log(1 + e^{-yf(x)})\]",Assignment 9 - SVM vs Logistic Regression,svm logistic-regression hinge-loss log-likelihood margin,,,,,,"SVM's hinge loss is 'sparse' - it's zero for correctly classified points beyond the margin, making SVMs focus only on difficult cases (support vectors). Logistic regression's smooth log loss considers all points, providing probability estimates. SVM is like a bouncer who only cares about troublemakers near the boundary, while logistic regression is like a poll taker who considers everyone's opinion with varying weights."
How does the regularization parameter C affect SVM behavior?,"Higher C values create harder margins with less tolerance for misclassification, while lower C values allow softer margins with more flexibility","\[\min_{w,b,\xi} \frac{1}{2}||w||^2 + C\sum_i \xi_i \text{ subject to } y_i(w^T x_i + b) \geq 1 - \xi_i\]",Assignment 9 - SVM Regularization,regularization c-parameter soft-margin overfitting bias-variance,,,,,,"C controls the bias-variance tradeoff: high C can overfit by trying to classify every training point perfectly, creating complex boundaries. Low C prioritizes simplicity and generalization over perfect training accuracy. It's like tuning the strictness of a rule - too strict (high C) and you might miss the bigger picture, too lenient (low C) and you might not capture important details. The optimal C depends on your data's noise level and complexity."
What is the decision function in SVMs and how is it computed using the kernel trick?,The decision function computes signed distance from the hyperplane using weighted kernel evaluations with support vectors,"\[f(x) = \sum_{i \in SV} \alpha_i y_i K(x, x_i) + b\]",Assignment 9 - Decision Function,decision-function kernel-trick support-vectors prediction,,,,,,"The decision function is like a weighted voting system where each support vector casts a vote (alpha_i * y_i) based on its similarity to the test point (K(x, x_i)). Points vote stronger when they're more similar (high kernel value) and when they were important during training (high alpha). The bias b shifts the overall decision threshold. The sign determines the class, while the magnitude indicates confidence in the prediction."

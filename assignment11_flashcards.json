{
  "assignment11_flashcards": [
    {
      "front": "What is the mathematical formula for 2D convolution output size with padding and stride?",
      "back": "Output size = (Input size + 2×Padding - Filter size) / Stride + 1",
      "formula": "\\[O = \\frac{I + 2P - F}{S} + 1\\]",
      "source": "Assignment 11 - Convolutional Operations",
      "tags": "convolution cnn padding stride",
      "extra": "ANALOGY: Like calculating how many steps you can take across a room - depends on room size (input), your stride length (stride), the size of your shoes (filter), and whether you can start from the wall (padding).\n\nKEY INSIGHT: This formula determines spatial dimensions throughout your CNN - critical for ensuring layer compatibility and designing proper architectures.\n\nTECHNICAL BREAKDOWN:\n• I: Input spatial dimension (height or width)\n• P: Padding added to each side (0 for 'valid', calculated for 'same')\n• F: Filter/kernel size (typically odd numbers like 3, 5, 7)\n• S: Stride (step size, typically 1 or 2)\n\nCOMMON SCENARIOS:\n• Same padding: P = (F-1)/2, keeps input/output same size when S=1\n• Valid padding: P = 0, output shrinks by (F-1)\n• Stride=2: Halves spatial dimensions (downsampling)\n\nPRACTICAL EXAMPLES:\n• Input 32×32, filter 3×3, padding 1, stride 1 → output 32×32 (preserved)\n• Input 32×32, filter 3×3, padding 0, stride 1 → output 30×30 (shrinks)\n• Input 32×32, filter 3×3, padding 1, stride 2 → output 16×16 (downsampled)\n\nCONNECTIONS: Related to signal processing, architecture design, memory planning\n\nCRITICAL: Must result in integer - fractional outputs indicate incompatible parameters"
    },
    {
      "front": "What are the key components needed to train a CNN in PyTorch?",
      "back": "Model (nn.Module), Loss function (criterion), Optimizer, Data loaders, Training loop with forward/backward passes",
      "formula": "",
      "source": "Assignment 11 - PyTorch Training",
      "tags": "pytorch training cnn workflow",
      "extra": "ANALOGY: Like cooking - you need a recipe (model), ingredients (data), technique (optimizer), and process (training loop) to create the final dish.\n\nKEY INSIGHT: PyTorch training follows a consistent pattern regardless of model complexity - the same fundamental loop applies to simple MLPs and complex transformers.\n\nTECHNICAL: Essential workflow: 1) Define model inheriting nn.Module with __init__ and forward() 2) Create criterion (e.g., CrossEntropyLoss) 3) Set optimizer (e.g., Adam) 4) Loop: optimizer.zero_grad() → forward pass → loss.backward() → optimizer.step()\n\nCONNECTIONS: Related to automatic differentiation, gradient descent, deep learning frameworks\n\nPRACTICAL: This pattern scales from toy problems to production systems - master these basics and you can train any neural network."
    },
    {
      "front": "What effects do different convolutional filters have on images?",
      "back": "Edge detection (gradients), blurring (smoothing), sharpening (high-pass), and directional features depending on filter weights",
      "formula": "",
      "source": "Assignment 11 - Filter Effects",
      "tags": "convolution filters edge-detection image-processing",
      "extra": "ANALOGY: Filters are like specialized glasses - edge detection glasses highlight boundaries, blur glasses smooth everything out, sharpening glasses make details pop.\n\nKEY INSIGHT: Different filter weights create different feature detectors - this is the foundation of how CNNs learn hierarchical features automatically.\n\nTECHNICAL: Vertical edge detector [-1,0,1; -1,0,1; -1,0,1] finds vertical edges. Horizontal [−1,−1,−1; 0,0,0; 1,1,1] finds horizontal edges. Gaussian blur smooths images. Sharpening enhances edges.\n\nCONNECTIONS: Signal processing, computer vision, feature extraction, Gabor filters\n\nPRACTICAL: Understanding filter effects helps debug CNN behavior and design custom architectures for specific tasks."
    },
    {
      "front": "How do you improve CNN performance beyond the baseline architecture?",
      "back": "Data augmentation, deeper networks, dropout regularization, better optimizers, learning rate scheduling, residual connections",
      "formula": "",
      "source": "Assignment 11 - Model Improvement",
      "tags": "cnn optimization performance data-augmentation",
      "extra": "ANALOGY: Like improving athletic performance - you need better training data (augmentation), better technique (architecture), and better coaching (optimization).\n\nKEY INSIGHT: CNN improvement requires a multi-pronged approach - no single technique will dramatically boost performance, but combining them creates synergistic effects.\n\nTECHNICAL: 1) Data augmentation (rotation, flipping, cropping) increases effective dataset size 2) Architectural improvements (more layers, dropout, residual connections) 3) Training improvements (Adam optimizer, learning rate scheduling, early stopping)\n\nCONNECTIONS: Regularization theory, data efficiency, modern architecture design (ResNet, DenseNet)\n\nPRACTICAL: Start with data augmentation (biggest bang for buck), then tune architecture, finally optimize training - systematic approach prevents diminishing returns."
    },
    {
      "front": "What is the purpose of data normalization in CNN preprocessing?",
      "back": "Standardizes input values to improve training stability and convergence speed",
      "formula": "\\[x_{norm} = \\frac{x - \\mu}{\\sigma}\\]",
      "source": "Assignment 11 - Data Preprocessing",
      "tags": "normalization preprocessing cnn training",
      "extra": "ANALOGY: Like standardizing test scores - puts all inputs on equal footing so the network can learn patterns rather than being distracted by scale differences.\n\nKEY INSIGHT: Normalization prevents certain features from dominating due to scale differences and helps gradients flow better during backpropagation.\n\nTECHNICAL: CIFAR-10 typically normalized to [-1,1] using mean=0.5, std=0.5 for each RGB channel.\n\nCONNECTIONS: Data preprocessing, gradient flow, training stability\n\nPRACTICAL: Essential preprocessing step for stable CNN training across different datasets."
    },
    {
      "front": "What is the role of MaxPooling in CNN architectures?",
      "back": "Reduces spatial dimensions, provides translation invariance, and reduces computational cost while retaining important features",
      "formula": "",
      "source": "Assignment 11 - CNN Architecture",
      "tags": "maxpooling cnn dimensionality-reduction",
      "extra": "ANALOGY: Like summarizing a paragraph by keeping only the most important words - you lose detail but keep the essence.\n\nKEY INSIGHT: MaxPooling provides translation invariance and computational efficiency, but at the cost of spatial precision - a fundamental trade-off in CNN design.\n\nTECHNICAL: MaxPooling takes maximum value in each region (typically 2×2), reducing 32×32 to 16×16. Benefits: 1) Reduces parameters and computation 2) Provides translation invariance 3) Focuses on strongest activations\n\nCONNECTIONS: Dimensionality reduction, translation invariance, modern alternatives like strided convolutions\n\nPRACTICAL: Essential for managing computational cost in deep networks, though some modern architectures replace it with strided convolutions for learnable downsampling."
    },
    {
      "front": "How do you evaluate model performance during CNN training?",
      "back": "Monitor training/validation loss and accuracy, use separate test set for final evaluation, watch for overfitting signs",
      "formula": "\\[Accuracy = \\frac{Correct Predictions}{Total Predictions}\\]",
      "source": "Assignment 11 - Model Evaluation",
      "tags": "evaluation accuracy overfitting validation",
      "extra": "ANALOGY: Like studying for exams - practice tests (validation) help adjust your strategy, but the final grade (test set) is what matters.\n\nKEY INSIGHT: The gap between training and validation performance is your overfitting detector - monitor this religiously during training.\n\nTECHNICAL: Training loss should decrease steadily. Validation accuracy should improve initially. If training accuracy >> validation accuracy, you're overfitting. Test set gives final unbiased performance estimate.\n\nCONNECTIONS: Cross-validation, model selection, bias-variance tradeoff, generalization theory\n\nPRACTICAL: Use techniques like early stopping, dropout, or regularization if overfitting occurs. Never tune hyperparameters on the test set!"
    },
    {
      "front": "What is the relationship between stride, padding, and output spatial dimensions in CNNs?",
      "back": "Stride controls downsampling rate, padding preserves spatial dimensions, together they determine output size according to the convolution formula",
      "formula": "\\[Output = \\frac{Input + 2 \\times Padding - Kernel}{Stride} + 1\\]",
      "source": "Assignment 11 - CNN Spatial Dimensions",
      "tags": "stride padding convolution spatial-dimensions",
      "extra": "ANALOGY: Like planning a road trip - stride is how big steps you take (affects speed and detail seen), padding is adding buffer zones around the map borders.\n\nKEY INSIGHT: These parameters give you precise control over information flow through your network - the foundation of architecture design.\n\nTECHNICAL: Stride=1 preserves resolution but increases computation. Stride=2 halves dimensions, reducing computation but losing spatial detail. Padding='same' keeps dimensions constant, padding=0 shrinks output.\n\nCONNECTIONS: Architecture design, computational efficiency, receptive field calculation\n\nPRACTICAL: Critical for designing networks where layer outputs must match expected input dimensions. Example: 64×128 input with 3×3 kernel, stride=1, padding=1 gives 64×128 output."
    }
  ]
}